{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926069cb",
   "metadata": {},
   "source": [
    "# Codeup Individual Project: Predicting Vehicle Accident Severity\n",
    "\n",
    "The purpose of this project is to analyze the selected dataset, answer questions regarding the data, and develop a machine learning model to predict the severity of an accident based on human and environmental circumstances. I obtained the dataset for this project from https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents?resource=download.\n",
    "\n",
    "I am using this dataset for academic purposes only.\n",
    "\n",
    "Initial Questions:\n",
    "\n",
    "- What road conditions are most likely to result in an accident?\n",
    "- What time of day are accidents most likely to occur? What time of year are accidents most likely to occur?\n",
    "- Are there specific areas that are prone to crashes?\n",
    "\n",
    "Questions regarding time:\n",
    "\n",
    "- Have the number of accidents increased overall between 2016 and 2021?\n",
    "- Has the severity of accidents changed between 2016 and 2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccd1bf",
   "metadata": {},
   "source": [
    "## Project Utility\n",
    "\n",
    "- Predicting accident severity based on environmental conditions and road features can be useful for first responders, drivers, and rideshare companies. Accurate predictions can help first responders gauge the amount of services and emergency aid needed based on the most commonly required responses for each level of severity. Drivers can get accurate updates on how long traffic will be delayed and if alternate routes are needed. Future utility includes providing warnings to drivers and first responders of potential accident locations and severity based on current environmental and road conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b2757",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "- The dataset was downsampled using random sampling due to an imbalance in the target variable. I split the downsampled data into train, validate, and test using a 60/20/20 split stratefied on severity. The total number of observations after removing nulls and outliers and downsampling was 191,685.\n",
    "- The selected model is a random forest classifier with a depth of 16 and minimum sample leaf size of 35. I selected 23 features for the final model based on visualizations and statistical tests. I used a random_seed of 217 for reproducibility. The baseline prediction for the training set was .34. The model performed above baseline accuracy at .71 on train and .69 on validate, indicating that the decision tree was not overfit. The model scored .69 on the test set as well. The model was 34 percent more accurate than baseline on the validate and test sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a0a17",
   "metadata": {},
   "source": [
    "## Acquisition and Preparation\n",
    "\n",
    "- Acquire the dataset from Kaggle and save to a local csv\n",
    "- Prepare the data with the intent to discover the main predictors of crash severity; clean the data and encode categorical features if necessary; ensure that the data is tidy\n",
    "- Write functions to wrangle the data and save to wrangle.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106db715",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (explore.py, line 37)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3397\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m in \u001b[0;35m<cell line: 7>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import explore\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/codeup-data-science/individual-project/explore.py:37\u001b[0;36m\u001b[0m\n\u001b[0;31m    sns.countplot(x=train.severity, hue=train.civil_twilight)plt.xlabel('Severity')\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# required imports for the project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import explore\n",
    "import wrangle\n",
    "import model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac096d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the dataset using wrangle.py file\n",
    "df = wrangle.wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify dataset was wrangled successfully\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c47c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample severity level 2 to balance the dataset, drop severity level 1\n",
    "df = wrangle.downsample_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for the year the accident occurred\n",
    "df['year'] = df.start_time.dt.year\n",
    "# create a new column for the month the accident occurred\n",
    "df['month'] = df.start_time.dt.month\n",
    "# create a new column for the day of the month the accident occurred\n",
    "df['day'] = df.start_time.dt.day\n",
    "# create a new column for the hour of the day the accident occurred\n",
    "df['hour'] = df.start_time.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that all columns are present and there are no null values\n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262f109",
   "metadata": {},
   "source": [
    "### Acquisition and Preparation Takeaways\n",
    "\n",
    "- Four columns have been dropped: number, country, airport_code, and turning_loop. These columns are not necessary or useful for analysis at this time.\n",
    "- All observations with null values were dropped.\n",
    "- Outliers for wind_speed and wind_chill were dropped, and total_time was limited to accidents with a duration of one day or less.\n",
    "- The final dataset has 191,685 observations. The target variable has been reduced from 4 categories to 3. One category was dropped because the observations all occurred within a 9-month span during the beginning of the Covid-19 pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45535d84",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "- Explore the data:\n",
    "    - Univariate, bivariate, and multivariate analyses; statistical tests for significance, find the three primary features affecting crash severity; use distance, precipitation, and visibility for the first model\n",
    "- Create graphical representations of the analyses\n",
    "- Answer initial questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of each feature and the target variable\n",
    "df.hist(figsize=[26,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7eabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset using a 60/20/20 split, stratified on the target variable\n",
    "train, validate, test = explore.split_data(df, 'severity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the data was split correctly\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b63928",
   "metadata": {},
   "source": [
    "#### Are accidents more likely to occur during the day or at night?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a76b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graphs for the relationship between day/night and accident severity\n",
    "explore.plot_day_night(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44140d4b",
   "metadata": {},
   "source": [
    "Statistical test for independence between severity and sunrise_sunset:\n",
    "- H0: There is no association between the severity of an accident and whether it is day or night.\n",
    "- Ha: There is an association between the severity of an accident and whether it is day or night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct a chi2 test of independence for sunrise_sunset and severity\n",
    "explore.stat_chi2(train.severity, train.sunrise_sunset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf34135",
   "metadata": {},
   "source": [
    "- Crashes occur more often during the day, but there is generally more traffic during daytime hours. An interesting finding is that accidents that occur more frequently during nighttime on the sunrise_sunset angle than on the other angles. This may be because sunlight is still visible when the sun reaches the sunrise_sunset angle, but visibility is reduced during this particular time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90eee7",
   "metadata": {},
   "source": [
    "#### Are there specific areas that are prone to crashes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd09ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relationships between individual road features and accident severity\n",
    "explore.countplot_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a9b8be",
   "metadata": {},
   "source": [
    "- Most of the accidents occurred when these particular features were NOT present, but there are certain features, such as traffic signals, crossings, and junctions, where accidents occur more often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20e1d3",
   "metadata": {},
   "source": [
    "#### What road and environmental conditions are most likely to result in an accident?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relationships between environmental conditions and accident severity\n",
    "explore.barplot_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22faf3",
   "metadata": {},
   "source": [
    "- Severe accidents tend to cover more distance that moderate crashes. Precipitation seems to have an effect on the severity of a crash. Wind speed also appears to play a role in crash severity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fa008",
   "metadata": {},
   "source": [
    "Statistical test for severity and distance:\n",
    "- H0: There is no mean difference of accident distance between the three severity categories.\n",
    "- Ha: There is a mean difference of accident distance between the three severity categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for distance based on severity levels\n",
    "sev2_dist = train[train.severity==2]['distance']\n",
    "sev3_dist = train[train.severity==3]['distance']\n",
    "sev4_dist = train[train.severity==4]['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 2 distance and severity 3 distance\n",
    "explore.stat_levene(sev2_dist, sev3_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cefc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 2 distance and severity 4 distance\n",
    "explore.stat_levene(sev2_dist, sev4_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0bb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 3 distance and severity 4 distance\n",
    "explore.stat_levene(sev3_dist, sev4_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the Kruskal-Wallis one-way analysis of variance for nonparametric data\n",
    "explore.stat_kruskal(sev2_dist, sev3_dist, sev4_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e0c67",
   "metadata": {},
   "source": [
    "Statistical test for severity and precipitation:\n",
    "- H0: There is no mean difference in precipitation between the three severity categories.\n",
    "- Ha: There is a mean difference in precipitation between the three severity categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for precipitation for each severity level\n",
    "sev2_rain = train[train.severity==2]['precipitation']\n",
    "sev3_rain = train[train.severity==3]['precipitation']\n",
    "sev4_rain = train[train.severity==4]['precipitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4918dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 2 precipitation and severity 3 precipitation\n",
    "explore.stat_levene(sev2_rain, sev3_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b567dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 2 precipitation and severity 4 precipitation\n",
    "explore.stat_levene(sev2_rain, sev4_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81675560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 4 precipitation and severity 3 precipitation\n",
    "explore.stat_levene(sev4_rain, sev3_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a54871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the Kruskal-Wallis one-way analysis of variance for nonparametric data\n",
    "explore.stat_kruskal(sev2_rain, sev3_rain, sev4_rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db1e69",
   "metadata": {},
   "source": [
    "Statistical test for severity and visibility:\n",
    "- H0: There is no mean difference in visibility between the three severity categories.\n",
    "- Ha: There is a mean difference in visibility between the three severity categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for visibility for each severity level\n",
    "sev2_vis = train[train.severity==2]['visibility']\n",
    "sev3_vis = train[train.severity==3]['visibility']\n",
    "sev4_vis = train[train.severity==4]['visibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 2 visibility and severity 3 visibility\n",
    "explore.stat_levene(sev2_vis, sev3_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 2 visibility and severity 4 visibility\n",
    "explore.stat_levene(sev2_vis, sev4_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1092338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for equal variance between severity 4 visibility and severity 3 visibility\n",
    "explore.stat_levene(sev4_vis, sev3_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the Kruskal-Wallis one-way analysis of variance for nonparametric data\n",
    "explore.stat_kruskal(sev2_vis, sev3_vis, sev4_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06126c23",
   "metadata": {},
   "source": [
    "#### What time of day are accidents most likely to occur? What time of year are accidents most likely to occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of accidents based on different measurements of time\n",
    "explore.plot_time_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc30363",
   "metadata": {},
   "source": [
    "- Accidents increase from April to June, and increase again in December. This coincides with periods where children are out of school and families are traveling. These months tend to have more precipitation in certain regions as well.\n",
    "- Accidents appear to occur most frequently during afternoon rush-hour traffic, when most people are traveling home from work or school."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f46017d",
   "metadata": {},
   "source": [
    "### Exploration Takeaways\n",
    "\n",
    "Initial exploration: \n",
    "\n",
    "- The target variable caused the dataset to be unbalanced, as most accidents were classified as severity level 2. This resulted in a baseline accuracy using the mode to be 93 percent. In order to balance the dataset, I took a random sample of 65,000 level-2 severity accidents from the total dataset using random_seed=217 for reproducibility. I concatenated this sample with the total observations from the other severity classes into a new dataframe. This sampling did not take into account any features, so important data about key features of a crash may have been lost.\n",
    "\n",
    "Time exploration:\n",
    "\n",
    "- When resampling for start_time, additional visualization indicated that more accidents occur in April through June, and between the hours of 2pm and 6pm. Perhaps using start time as a feature will improve the models' performance. The number of accidents has increased year over year, but this may be due to improved data collection and digitized accident information over the years. \n",
    "\n",
    "Statistical exploration:\n",
    "\n",
    "- Statistical testing using a Kruskal-Wallis one-way analysis of variance showed significant differences in the three initial features selected for modeling (precipitation, visibility, and distance). Chi^2 test of severity and whether it is day or night (according to sunrise/sunset angle) showed an association.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad36f59",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "- Train and test four models:\n",
    "    - Establish a baseline using the mode for severity\n",
    "    - Select key features and train multiple classification models (Decision Tree, Random Forest, KNN, Logistic Regression)\n",
    "    - Test the model on the validate set, adjust for overfitting if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most observed severity level\n",
    "train.severity.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a baseline prediction using the mode\n",
    "baseline = len(train[train.severity==2]) / len(train)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1664b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select significant features for modeling based on visualization and statistical testing\n",
    "cols = ['distance','precipitation','visibility','humidity','temperature','pressure','wind_speed','amenity','bump', \n",
    "       'crossing','give_way','junction','no_exit','railway','roundabout','station','stop','traffic_calming',\n",
    "       'traffic_signal','sunrise_sunset','year','month', 'hour']\n",
    "# create the dataframes for train features and target\n",
    "X_train, y_train = train[cols], train.severity\n",
    "# create the dataframes for validate features and target\n",
    "X_validate, y_validate = validate[cols], validate.severity\n",
    "# create the dataframes for test features and target\n",
    "X_test, y_test = test[cols], test.severity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ec8d7",
   "metadata": {},
   "source": [
    "#### Decision Tree Model, Depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd960701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree model function from model.py with a selected depth of 8\n",
    "model.tree_model(X_train, y_train, X_validate, y_validate, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229add3",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest function from model.py with a depth of 16 and 35 sample leaf size\n",
    "model.rand_forest(X_train, y_train, X_validate, y_validate, 16, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e33924",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors Model, Scaled, n=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e407e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the object, put it into the variable scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the object to my data:\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01626022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn model function from model.py with 40 neighbors\n",
    "model.knn_model(X_train_scaled, y_train, X_validate_scaled, y_validate, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a0948",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1113d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model function from model.py \n",
    "model.log_model(X_train, y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ddaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model using scaled data\n",
    "model.log_model(X_train_scaled, y_train, X_validate_scaled, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3095877",
   "metadata": {},
   "source": [
    "### Modeling Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4622d0",
   "metadata": {},
   "source": [
    "- The Decision Tree Classifier with a depth of 8 had a 68 percent accuracy on the training set and a 67 percent accuracy on validate. The model had high F1-scores for severity levels 2 and 3, but struggled to accurately predict level 4. This model provided a 33 percent increase in accuracy above the baseline.\n",
    "\n",
    "- The Random Forest Model with a depth of 16 and minimum sample leaf of 35 had a 71 percent accuracy on train and 69 percent accuracy on validate. This model has the most potential for tuning with hyperparameters and feature engineering. Random Forest was 34 percent more accurate on validate than the baseline prediction.\n",
    "\n",
    "- The K Nearest Neighbors Model with 40 neighbors had an accuracy of 65 percent on train and 63 percent on validate. The features were scaled prior to training the model. The model was 29 percent more accurate than baseline.\n",
    "\n",
    "- The Logistic Regression Model had a 60 percent accuracy on train and 61 percent on validate using scaled data. The accuracy was 49 percent on train and validate with unscaled data. This model was not tuned and may perform better with specific arguments and fine tuning. The model was 26 percent more accurate than baseline.\n",
    "\n",
    "- I will use the Random Forest model for testing because it performed best on precision, accuracy, and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2c314",
   "metadata": {},
   "source": [
    "## Test the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf36353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model was selected; test the model using a function from model.py\n",
    "model.test_forest(X_train, y_train, X_test, y_test, 16, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de33aaa",
   "metadata": {},
   "source": [
    "## Conclusions, Recommendations, and Next Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcbc2e",
   "metadata": {},
   "source": [
    "- The target variable caused the dataset to be unbalanced, as most accidents were classified as severity level 2. This resulted in a baseline accuracy using the mode to be 93 percent. In order to balance the dataset, I took a random sample of 65,000 level-2 severity accidents from the total dataset using random_seed=217 for reproducibility. I concatenated this sample with the total observations from the other severity classes into a new dataframe of 215,240 observations. This sampling did not take into account any features, so important data about key features of a crash may have been lost. Exploration of this data revealed that crashes of severity level 1 were limited to a nine-month time period in 2020; I dropped this severity level because it is in itself an outlier.\n",
    "\n",
    "\n",
    "- The minimum viable product model is a decision tree classifier with a maximum depth of 4. I selected three features for the initial model: distance, precipitation, and visibility. I selected these features based on visualizations and statistical tests. I used a random_seed of 217 for reproducibility. The baseline prediction for the training set was .302. The model performed above baseline accuracy at .42 on train and .41 on validate, indicating that the decision tree was not overfit. \n",
    "\n",
    "\n",
    "- Subsequent models with other features added increased accuracy by another 30 percent on average. Decision Tree, Random Forest, K Nearest Neighbors, and Logistic Regression were used. I scaled the features for train and validate prior to using the KNN model, but I did not scale the test set because this model was not selected for testing. I evaluated multiple depths and sample sizes for each model. The selected parameters provided the highest performance without overfitting. \n",
    "\n",
    "\n",
    "- When resampling the start_time, additional visualization indicated that more accidents occur in April through June, and between the hours of 2pm and 6pm. Using month and hour as features will likely improve the models' performance. The number of accidents has increased year over year, but this may be due to improved data collection and digitized accident information over the years. \n",
    "\n",
    "\n",
    "- The Random Forest Model performed best overall, and when evaluated on the test set, achieved the same overall level of accuracy as train and validate, indicating that the model was not overfit. I used 23 features, 20 from the dataset and 3 engineered features using the start time. \n",
    "\n",
    "\n",
    "- I recommend using this model if real-time information of the selected features is available when a crash occurs. The model assumes that severity has been established based on specific parameters and that previous crash data was correctly classified. I also recommend adding posted speed limits to the dataset and whether the area has a special classification, e.g. construction zone, school zone, etc. Information about injuries and fatalities for previous crashes could provide valuable insight on what emergency services will be needed based on the predicted severity of the crash.\n",
    "\n",
    "\n",
    "- If I had more time, I would explore the coordinate data to see if there are certain areas that experience recurring crashes. I would also like to know more about traffic patterns in the area of the crash to see if traffic density has a significant impact on crash severity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0aea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
